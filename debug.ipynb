{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python362jvsc74a57bd0d8c3bc2de3ad543e78c2abea382c239044b23893d84e9a9a3a046aff7da94b5e",
   "display_name": "Python 3.6.2 64-bit ('implicit-pose': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.3650)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.layers.topology import TopologyModule\n",
    "\n",
    "topo = TopologyModule()\n",
    "a = torch.randn(2, 3, 4)\n",
    "b = topo(a)\n",
    "d = (b - a).mean()\n",
    "aa = []\n",
    "aa.append(d)\n",
    "print(sum(aa) / len(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 0.4460, -0.2561,  0.8519],\n         [-0.6642,  1.0791,  1.6099],\n         [-0.7533, -0.8015, -0.8411],\n         [-0.6531,  1.1243,  0.0605],\n         [-0.6303,  1.2920,  0.0657]],\n\n        [[ 0.9305, -0.5332, -0.6160],\n         [ 0.2539, -0.3506,  1.2770],\n         [-0.8902, -1.2303,  0.2275],\n         [-0.2055, -0.5305, -0.0584],\n         [ 0.2947, -1.6534,  2.1372]]])\ntensor([[[0.4338, 0.0711, 0.2366],\n         [0.1430, 0.2703, 0.5049],\n         [0.1308, 0.0412, 0.0435],\n         [0.1445, 0.2828, 0.1072],\n         [0.1479, 0.3345, 0.1078]],\n\n        [[0.3967, 0.2483, 0.0365],\n         [0.2017, 0.2980, 0.2423],\n         [0.0642, 0.1237, 0.0848],\n         [0.1274, 0.2490, 0.0637],\n         [0.2101, 0.0810, 0.5727]]])\ntensor([[3, 3, 3],\n        [0, 2, 1]])\ntensor([[[-0.8351, -2.6433, -1.4414],\n         [-1.9452, -1.3081, -0.6834],\n         [-2.0343, -3.1887, -3.1345],\n         [-1.9341, -1.2629, -2.2329],\n         [-1.9113, -1.0952, -2.2277]],\n\n        [[-0.9246, -1.3931, -3.3106],\n         [-1.6012, -1.2105, -1.4177],\n         [-2.7453, -2.0902, -2.4672],\n         [-2.0606, -1.3904, -2.7531],\n         [-1.5604, -2.5133, -0.5574]]])\ntensor(1.6437)\ntensor(-1.6437)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "ce = nn.CrossEntropyLoss()\n",
    "so = nn.Softmax(dim=1)\n",
    "a = torch.randn(2, 5, 3) # (B, C, N)\n",
    "print(a)\n",
    "aa = so(a)\n",
    "b = torch.empty(2, 3, dtype=torch.long).random_(5) # (B, N)\n",
    "print(aa)\n",
    "print(b)\n",
    "loga = torch.log(aa)\n",
    "print(loga)\n",
    "loss = ce(a, b)\n",
    "print(loss)\n",
    "\n",
    "ans = 0\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ans = ans + loga[i,b[i,j],j]\n",
    "print(ans / 6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}